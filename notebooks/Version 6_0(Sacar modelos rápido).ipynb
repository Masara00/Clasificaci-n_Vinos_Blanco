{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas pre drop: 4898\n",
      "Columnas post drop: 4870\n",
      "Len original: 4870\n",
      "Len sin outliers en residual sugar: 4863\n",
      "Len original: 4863\n",
      "Len sin outliers en citric acid: 4598\n",
      "Len original: 4598\n",
      "Len sin outliers en chlorides: 4426\n",
      "Len original: 4426\n",
      "Len sin outliers en bound sulfur dioxide: 4398\n",
      "Len original: 4398\n",
      "Len sin outliers en free sulfur dioxide: 4343\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "import xgboost\n",
    "    # NOTA\n",
    "    # xgboost.XGBRFClassifier En cada secuencia tiene un RandomForest\n",
    "    # xgboost.XGBClassifier sin RandomForest\n",
    "# ------------------\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "    # NOTA\n",
    "    # Hay que poner las etiquetas manualmente. El otro es 'from sklearn.pipeline import make_pipeline'\n",
    "# ------------------\n",
    "# MÃ©tricas de validaciÃ³n\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "# ------------------\n",
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# ------------------\n",
    "# Balanceo\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "# ------------------\n",
    "# Otras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ------------------\n",
    "# Pickle\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# LECTURA CSV\n",
    "vinos = pd.read_csv('data/winequalityN.csv')\n",
    "\n",
    "\n",
    "blanco=vinos[vinos['type']=='white'].reset_index()\n",
    "blanco = blanco.drop(['index', 'type'], axis=1)\n",
    "\n",
    "\n",
    "print(\"Columnas pre drop:\", len(blanco))\n",
    "blanco = blanco.dropna()\n",
    "print(\"Columnas post drop:\", len(blanco))\n",
    "\n",
    "\n",
    "# Cambiamos la variable Target para que sea solo entre 'aptos=1' y 'no aptos=0'\n",
    "my_dict={3:0, 4:0, 5:0,\n",
    "        6:1, 7:1, 8:1, 9:1}\n",
    "blanco['apto']= blanco['quality'].map(my_dict)\n",
    "blanco = blanco.drop(['quality'], axis=1)\n",
    "\n",
    "\n",
    "blanco.insert(5,'bound sulfur dioxide', (blanco['total sulfur dioxide']-blanco['free sulfur dioxide']))\n",
    "blanco = blanco.drop(['total sulfur dioxide'], axis=1)\n",
    "\n",
    "blanco = blanco.drop(['density'], axis=1)\n",
    "\n",
    "from scipy.stats import iqr\n",
    "\n",
    "def outliers_quantie(df, feature, param=1.5):  \n",
    "        \n",
    "    iqr_ = iqr(df[feature], nan_policy='omit')\n",
    "    q1 = np.nanpercentile(df[feature], 25)\n",
    "    q3 = np.nanpercentile(df[feature], 75)\n",
    "    \n",
    "    th1 = q1 - iqr_*param\n",
    "    th2 = q3 + iqr_*param\n",
    "    \n",
    "    return df[(df[feature] >= th1) & (df[feature] <= th2)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Len original:\", len(blanco))\n",
    "blanco = outliers_quantie(blanco, 'residual sugar')\n",
    "print(\"Len sin outliers en residual sugar:\", len(blanco))\n",
    "\n",
    "print(\"Len original:\", len(blanco))\n",
    "blanco = outliers_quantie(blanco, 'citric acid')\n",
    "print(\"Len sin outliers en citric acid:\", len(blanco))\n",
    "\n",
    "print(\"Len original:\", len(blanco))\n",
    "blanco = outliers_quantie(blanco, 'chlorides')\n",
    "print(\"Len sin outliers en chlorides:\", len(blanco))\n",
    "\n",
    "print(\"Len original:\", len(blanco))\n",
    "blanco = outliers_quantie(blanco, 'bound sulfur dioxide')\n",
    "print(\"Len sin outliers en bound sulfur dioxide:\", len(blanco))\n",
    "\n",
    "print(\"Len original:\", len(blanco))\n",
    "blanco = outliers_quantie(blanco, 'free sulfur dioxide')\n",
    "print(\"Len sin outliers en free sulfur dioxide:\", len(blanco))\n",
    "\n",
    "\n",
    "X = blanco.iloc[:,:-1]\n",
    "y = blanco['apto']\n",
    "\n",
    "seed=33\n",
    "\n",
    "ros = RandomOverSampler(random_state=seed)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ros, y_ros, test_size=0.2, stratify=y_ros, random_state=seed)\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                       ('kbest', SelectKBest()),\n",
    "                       ('classifier', LogisticRegression(random_state=seed))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_params = {'kbest__k': [8,9,10],\n",
    "#               'classifier': [SVC()],\n",
    "#               'classifier__C': [0.5,0.8,1],\n",
    "#               'classifier__kernel': ['linear','rbf','sigmoid']\n",
    "# }\n",
    "# Accuracy Score 0.7793505412156536 \n",
    "# Best model. Best Params {'classifier': SVC(C=1), 'classifier__C': 1, 'classifier__kernel': 'rbf', 'kbest__k': 10} \n",
    "\n",
    "\n",
    "# log_params = {'kbest__k': [8,9,10],\n",
    "#               'classifier': [LogisticRegression()],\n",
    "#               'classifier__penalty': ['l1','l2'],\n",
    "#               'classifier__C': np.logspace(0,2,5)\n",
    "# }\n",
    "\n",
    "# Best model. Best Params {'classifier': LogisticRegression(), 'classifier__C': 1.0, 'classifier__penalty': 'l2', 'kbest__k': 9} \n",
    "# Accuracy Score 0.7185678601165695 \n",
    "\n",
    "\n",
    "# knn_params = {'kbest__k': [8,9,10],\n",
    "#               'classifier': [KNeighborsClassifier()],\n",
    "#               'classifier__n_neighbors': [5,10,12,17,20],\n",
    "#               'classifier__weights': ['uniform','distance']\n",
    "# }\n",
    "# 'classifier__n_neighbors': 17, 'classifier__weights': 'distance', 'kbest__k': 10\n",
    "# Accuracy Score 0.9075770191507078 \n",
    "\n",
    "\n",
    "\n",
    "# rf_params = {'kbest__k': [8,9,10],\n",
    "#               'classifier': [RandomForestClassifier()],\n",
    "#               'classifier__n_estimators': [50,100,150],\n",
    "#               'classifier__max_depth': [2,3,4,5,6,7],\n",
    "#               'classifier__min_samples_leaf': [1,3,5]\n",
    "# }\n",
    "# 'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 150, 'kbest__k': 10\n",
    "# Accuracy Score 0.829308909242298 \n",
    "\n",
    "\n",
    "\n",
    "# gb_params = {'kbest__k': [8,9,10],\n",
    "#               'classifier': [GradientBoostingClassifier()],\n",
    "#             #   'classifier__max_depth': [2,3,4,5,6],\n",
    "#               'classifier__max_depth': [5,6,7],\n",
    "#               'classifier__n_estimators': [430,440,445,450],\n",
    "#               'classifier__learning_rate': [0.1,0.15,0.2,0.25]\n",
    "# }\n",
    "\n",
    "\n",
    "# ada_params = {'kbest__k': [8,9,10],\n",
    "#               'classifier': [AdaBoostClassifier()],\n",
    "#               'classifier__n_estimators': [150,200,300,350],\n",
    "#               'classifier__learning_rate': [0.3,0.5,0.7,1]\n",
    "# }\n",
    "# 'classifier__learning_rate': 0.7, 'classifier__n_estimators': 300, 'kbest__k': 10} \n",
    "# Accuracy Score 0.7535387177352206 \n",
    "\n",
    "\n",
    "xgb_params = {'kbest__k': [8,9,10],\n",
    "              'classifier': [xgboost.XGBRFClassifier()],\n",
    "              'classifier__n_estimators': [175,200,225],\n",
    "              'classifier__learning_rate': [0.01,0.02,0.03,0.05]\n",
    "}\n",
    "# Accuracy Score 0.8018318068276437 \n",
    "\n",
    "# search_space = [svm_params, log_params, knn_params, rf_params, gb_params, ada_params, xgb_params]\n",
    "search_space = [xgb_params]\n",
    "\n",
    "clf = GridSearchCV(estimator=pipe, param_grid=search_space, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model. Best Score 0.7734749115136372 \n",
      " --------------------------------------------------\n",
      "Best model. Best Params {'classifier': XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                colsample_bylevel=None, colsample_bytree=None,\n",
      "                early_stopping_rounds=None, enable_categorical=False,\n",
      "                eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
      "                importance_type=None, interaction_constraints=None,\n",
      "                learning_rate=0.01, max_bin=None, max_cat_to_onehot=None,\n",
      "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "                n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "                objective='binary:logistic', predictor=None, random_state=None,\n",
      "                reg_alpha=None, sampling_method=None, ...), 'classifier__learning_rate': 0.01, 'classifier__n_estimators': 200, 'kbest__k': 10} \n",
      " --------------------------------------------------\n",
      "Accuracy Score 0.8018318068276437 \n",
      " --------------------------------------------------\n",
      "Confusion Matrix \n",
      " [[486 115]\n",
      " [123 477]] \n",
      " --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_model.best_estimator_.predict(X_test)\n",
    "print('Best model. Best Score', best_model.best_score_, '\\n','-'*50)\n",
    "print('Best model. Best Params', best_model.best_params_, '\\n','-'*50)\n",
    "print('Accuracy Score', accuracy_score(y_test, y_pred), '\\n','-'*50)\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_test,y_pred), '\\n','-'*50)\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred, normalize='true'), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model_xgb.model', \"wb\") as archivo_salida:\n",
    "#     pickle.dump(best_model.best_estimator_, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('kbest', SelectKBest()),\n",
      "                ('classifier',\n",
      "                 XGBRFClassifier(base_score=0.5, booster='gbtree',\n",
      "                                 callbacks=None, colsample_bylevel=1,\n",
      "                                 colsample_bytree=1, early_stopping_rounds=None,\n",
      "                                 enable_categorical=False, eval_metric=None,\n",
      "                                 gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "                                 importance_type=None,\n",
      "                                 interaction_constraints='', learning_rate=0.01,\n",
      "                                 max_bin=256, max_cat_to_onehot=4,\n",
      "                                 max_delta_step=0, max_depth=6, max_leaves=0,\n",
      "                                 min_child_weight=1, missing=nan,\n",
      "                                 monotone_constraints='()', n_estimators=200,\n",
      "                                 n_jobs=0, num_parallel_tree=200,\n",
      "                                 objective='binary:logistic', predictor='auto',\n",
      "                                 random_state=0, reg_alpha=0,\n",
      "                                 sampling_method='uniform', ...))])\n"
     ]
    }
   ],
   "source": [
    "# Cargar Modelo\n",
    "# with open('model_xgb.model', \"rb\") as archivo_entrada:\n",
    "#     my_model = pickle.load(archivo_entrada)    \n",
    "# print(my_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "703e8db34bb7cdd00b82a89d91d2e2137d3ce887601c5554b79c7f8766c7193f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
